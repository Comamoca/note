現在v5.0まで出ている。
リポジトリ: https://github.com/PlayVoice/so-vits-svc-5.0

## 学習の仕方

学習データを用意する。

### リポジトリのクローン
普通にclone
リポジトリ内のディレクトリに移動しておく

### リサンプリング

学習データのサンプリングレートは16000Hzと48000Hzの2種類ある。

学習したデータはこのように配置する。
```
dataset_raw
├───speaker0
│   ├───xxx1-xxx1.wav
│   ├───...
│   └───Lxx-0xx8.wav
└───speaker1
    ├───xx2-0xxx2.wav
    ├───...
    └───xxx7-xxx007.wav
```

最新版は`dataset_raw`が`data_raw`に変わっている。そのまま配置して大丈夫そう。
また、キャラクターごとに`speaker0`のようにディレクトリを作成して配置することに注意。これをしなくても実行できてしまうけど良くない事が起こりそうだったので作成するのが無難そう。

あと初めに横着して数分程度のデータを直に読み込ませたらエラーになったので、15秒以内に分割したほうが良さそう。

### 16000Hzの場合

#### リサンプリング

ローカルに`./data_svc/waves-16k`**というディレクトリが無いか**確認する。このディレクトリがあると実行時にエラーになるのであった場合は削除する。再実行時にも削除してから再実行する。

以下のコマンドを実行。
`python prepare/preprocess_a.py -w ./data_raw -o ./data_svc/waves-16k -s 16000`

> 可选的16000Hz提升到48000Hz，待完善~批处理
> (オプションの 16000Hz は 48000Hz に増やすことができ、改善される予定です ~ バッチ処理)

と書いてあるように、今後16000Hzで学習したデータを48000Hzに移行すること？が可能になるらしい。期待。

#### ピッチの抽出
`python prepare/preprocess_f0.py -w data_svc/waves-16k/ -p data_svc/pitch`

#### コンテンツ エンコーディングの抽出

Whisperを使うため、事前学習データが必要になる。[ここから](https://openaipublic.azureedge.net/main/whisper/models/345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1/medium.pt)データをダウンロード出来る。
このファイルを`whisper_pretrain`に配置する。